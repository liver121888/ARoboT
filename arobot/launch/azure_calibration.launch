<launch>
    <arg name="marker1Id"         default="33"/> <!-- change this if required-->
    <arg name="marker2Id"         default="999"/>
    <arg name="markerSize"        default="0.04"/>    <!-- change this, in m -->
    <arg name="dct_normalization" default="False" />
    <arg name="dct_filter_size"   default="2" />
    <arg name="marker1_frame"     default="marker_1_frame" />
    <arg name="marker2_frame"     default="marker_2_frame" />

    <!-- launch azure -->
    <include file="$(find azure_kinect_ros_driver)/launch/driver.launch"/>
    
    <!-- Launch the aruco detection node -->
    <node pkg="aruco_ros" type="double" name="aruco_simple">    
        <remap from="/camera_info" to="/rgb/camera_info" />
        <remap from="/image" to="/rgb/image_raw" />
        <param name="image_is_rectified" value="True"/>
        <param name="marker_size" value="$(arg markerSize)"/>
        <param name="marker_id1" value="$(arg marker1Id)"/>
        <param name="marker_id2" value="$(arg marker2Id)"/>
        <param name="normalizeImage" value="$(arg dct_normalization)"/>
        <param name="dct_components_to_remove" value="$(arg dct_filter_size)"/>
        <param name="parent_name" value="rgb_camera_link"/>
        <param name="child_name1" value="$(arg marker1_frame)" />
        <param name="child_name2" value="$(arg marker2_frame)" />
    </node> 

    <!-- launch the joint tf publisher for franka (reads joints from frankapy) -->
    <node name="robot_joint_converter" pkg="manipulation" type="robot_joint_converter.py" output="screen" />

    <!-- launch the easy handeye calibration GUI -->
    <include file="$(find arobot)/launch/calibrate.launch">
        <arg name="eye_on_hand" value="false"/>
        <arg name="start_rviz" value="false"/>

        <!-- you can choose any identifier, as long as you use the same for publishing the calibration -->
        <arg name="namespace_prefix" value="my_eob_calib"/>

        <!-- fill in the following parameters according to your robot's published tf frames -->
        <arg name="robot_base_frame" value="panda_link0"/>
        <arg name="robot_effector_frame" value="panda_end_effector"/>

        <!-- fill in the following parameters according to your tracking system's published tf frames -->
        <arg name="tracking_base_frame" value="rgb_camera_link"/>
        <arg name="tracking_marker_frame" value="marker_1_frame"/>

        <arg name="freehand_robot_movement" value="true" />
    </include>



</launch>
